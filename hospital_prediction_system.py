
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import json
import re
from collections import Counter
import io

# For web scraping (without API)
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
except:
    PLAYWRIGHT_AVAILABLE = False

# For sentiment analysis
try:
    from textblob import TextBlob
    TEXTBLOB_AVAILABLE = True
except:
    TEXTBLOB_AVAILABLE = False

# For machine learning predictions
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, mean_squared_error, r2_score

st.set_page_config(
    page_title="Hospital Review Analysis & Prediction - India",
    page_icon="üè•",
    layout="wide"
)

st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-card {
        background-color: #f0f8ff;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #4CAF50;
        margin: 10px 0;
    }
    .metric-box {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    </style>
""", unsafe_allow_html=True)

# Initialize session state
if 'scraped_data' not in st.session_state:
    st.session_state.scraped_data = []

if 'trained_model' not in st.session_state:
    st.session_state.trained_model = None

if 'prediction_results' not in st.session_state:
    st.session_state.prediction_results = {}

# Title
st.markdown('<h1 class="main-header">üè• Hospital Review Analysis & Prediction System</h1>', unsafe_allow_html=True)
st.markdown("### Extract Google Reviews, Analyze Sentiment & Make Predictions for Indian Hospitals")
st.markdown("**NO API KEY REQUIRED** - Uses Web Scraping")

# Create tabs
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üîç Data Collection", 
    "üìä Data Analysis", 
    "ü§ñ ML Predictions", 
    "üìà Insights Dashboard",
    "üíæ Export Data"
])

# TAB 1: Data Collection
with tab1:
    st.header("üì• Collect Hospital Review Data")

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("Method 1: Upload Existing Dataset")
        st.info("""
        **Pre-collected datasets available:**
        - Kaggle: Hospital Reviews Dataset (Bengaluru)
        - Use sample data from research papers
        - Upload your own CSV file
        """)

        uploaded_file = st.file_uploader(
            "Upload CSV file with hospital reviews", 
            type=['csv'],
            help="CSV should have columns: hospital_name, review_text, rating, location"
        )

        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ Loaded {len(df)} reviews")
                st.dataframe(df.head())

                # Store in session state
                st.session_state.scraped_data = df.to_dict('records')

            except Exception as e:
                st.error(f"Error loading file: {e}")

        st.markdown("---")

        st.subheader("Method 2: Use Sample Indian Hospital Data")

        if st.button("Load Sample Dataset", type="primary"):
            # Create comprehensive sample dataset for Indian hospitals
            sample_data = create_indian_hospital_dataset()
            st.session_state.scraped_data = sample_data
            st.success(f"‚úÖ Loaded {len(sample_data)} sample reviews from Indian hospitals")

            df_sample = pd.DataFrame(sample_data)
            st.dataframe(df_sample.head(10))

    with col2:
        st.subheader("Method 3: Web Scraping")

        st.warning("""
        **Web Scraping Setup Required:**

        Install dependencies:
        ```bash
        pip install playwright textblob
        playwright install
        ```

        **Note:** Web scraping requires:
        - Playwright browser automation
        - Proper handling of Google's anti-scraping
        - Ethical scraping practices
        """)

        if PLAYWRIGHT_AVAILABLE:
            st.success("‚úÖ Playwright installed")

            hospital_search = st.text_input(
                "Hospital Name to Search:",
                placeholder="Apollo Hospital Mumbai"
            )

            num_reviews = st.slider("Number of reviews to scrape:", 10, 100, 20)

            if st.button("üï∑Ô∏è Scrape Reviews"):
                with st.spinner("Scraping reviews... This may take a few minutes"):
                    try:
                        scraped = scrape_google_reviews_playwright(hospital_search, num_reviews)
                        st.session_state.scraped_data.extend(scraped)
                        st.success(f"‚úÖ Scraped {len(scraped)} reviews")
                    except Exception as e:
                        st.error(f"Scraping failed: {e}")
        else:
            st.error("‚ùå Playwright not installed")
            st.code("pip install playwright && playwright install")

    # Show current data
    if st.session_state.scraped_data:
        st.markdown("---")
        st.subheader(f"üìä Current Dataset: {len(st.session_state.scraped_data)} reviews")
        df_current = pd.DataFrame(st.session_state.scraped_data)
        st.dataframe(df_current.head(20))

# TAB 2: Data Analysis
with tab2:
    st.header("üìä Review Data Analysis")

    if not st.session_state.scraped_data:
        st.warning("‚ö†Ô∏è No data loaded. Please collect data in 'Data Collection' tab first.")
    else:
        df = pd.DataFrame(st.session_state.scraped_data)

        # Basic Statistics
        st.subheader("üìà Dataset Overview")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Total Reviews", len(df))
        with col2:
            avg_rating = df['rating'].mean() if 'rating' in df.columns else 0
            st.metric("Average Rating", f"{avg_rating:.2f} ‚≠ê")
        with col3:
            hospitals = df['hospital_name'].nunique() if 'hospital_name' in df.columns else 0
            st.metric("Unique Hospitals", hospitals)
        with col4:
            states = df['state'].nunique() if 'state' in df.columns else 0
            st.metric("States Covered", states)

        # Sentiment Analysis
        st.markdown("---")
        st.subheader("üòä Sentiment Analysis")

        if 'review_text' in df.columns and TEXTBLOB_AVAILABLE:
            with st.spinner("Analyzing sentiment..."):
                df['sentiment'] = df['review_text'].apply(analyze_sentiment)
                df['sentiment_score'] = df['review_text'].apply(get_sentiment_score)

                sentiment_counts = df['sentiment'].value_counts()

                col1, col2 = st.columns([1, 2])

                with col1:
                    st.markdown("**Sentiment Distribution:**")
                    for sentiment, count in sentiment_counts.items():
                        percentage = (count / len(df)) * 100
                        st.metric(sentiment, f"{count} ({percentage:.1f}%)")

                with col2:
                    # Create sentiment distribution chart data
                    st.markdown("**Sentiment Breakdown:**")
                    for sentiment, count in sentiment_counts.items():
                        percentage = (count / len(df)) * 100
                        st.progress(percentage / 100, text=f"{sentiment}: {percentage:.1f}%")

        # Hospital-wise analysis
        st.markdown("---")
        st.subheader("üè• Hospital-wise Performance")

        if 'hospital_name' in df.columns:
            hospital_stats = df.groupby('hospital_name').agg({
                'rating': ['mean', 'count'],
                'sentiment_score': 'mean' if 'sentiment_score' in df.columns else lambda x: 0
            }).round(2)

            hospital_stats.columns = ['Avg Rating', 'Review Count', 'Sentiment Score']
            hospital_stats = hospital_stats.sort_values('Avg Rating', ascending=False)

            st.dataframe(hospital_stats, use_container_width=True)

        # State-wise analysis
        if 'state' in df.columns:
            st.markdown("---")
            st.subheader("üìç State-wise Analysis")

            state_stats = df.groupby('state').agg({
                'rating': 'mean',
                'hospital_name': 'nunique'
            }).round(2)
            state_stats.columns = ['Avg Rating', 'Hospital Count']
            state_stats = state_stats.sort_values('Avg Rating', ascending=False)

            st.dataframe(state_stats, use_container_width=True)

        # Common themes analysis
        st.markdown("---")
        st.subheader("üí¨ Common Review Themes")

        if 'review_text' in df.columns:
            positive_reviews = df[df['rating'] >= 4]['review_text'].tolist()
            negative_reviews = df[df['rating'] <= 2]['review_text'].tolist()

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**Top Positive Keywords:**")
                pos_keywords = extract_keywords(positive_reviews, top_n=15)
                for word, freq in pos_keywords:
                    st.write(f"‚úÖ {word}: {freq}")

            with col2:
                st.markdown("**Top Negative Keywords:**")
                neg_keywords = extract_keywords(negative_reviews, top_n=15)
                for word, freq in neg_keywords:
                    st.write(f"‚ùå {word}: {freq}")

# TAB 3: ML Predictions
with tab3:
    st.header("ü§ñ Machine Learning Predictions")

    if not st.session_state.scraped_data:
        st.warning("‚ö†Ô∏è No data loaded. Please collect data first.")
    else:
        df = pd.DataFrame(st.session_state.scraped_data)

        st.subheader("Train Prediction Models")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### Model 1: Rating Prediction")
            st.info("""
            Predicts hospital rating based on:
            - Location (State/City)
            - Hospital type
            - Review sentiment
            - Service aspects
            """)

            if st.button("üéØ Train Rating Predictor", type="primary"):
                with st.spinner("Training model..."):
                    try:
                        model, metrics = train_rating_predictor(df)
                        st.session_state.trained_model = model

                        st.success("‚úÖ Model trained successfully!")
                        st.metric("R¬≤ Score", f"{metrics['r2']:.3f}")
                        st.metric("RMSE", f"{metrics['rmse']:.3f}")

                    except Exception as e:
                        st.error(f"Training failed: {e}")

        with col2:
            st.markdown("### Model 2: Sentiment Classifier")
            st.info("""
            Classifies review sentiment:
            - Positive
            - Neutral
            - Negative

            Based on review text analysis
            """)

            if st.button("üéØ Train Sentiment Classifier", type="primary"):
                with st.spinner("Training model..."):
                    try:
                        model, metrics = train_sentiment_classifier(df)

                        st.success("‚úÖ Model trained successfully!")
                        st.metric("Accuracy", f"{metrics['accuracy']:.3f}")
                        st.text("Classification Report:")
                        st.text(metrics['report'])

                    except Exception as e:
                        st.error(f"Training failed: {e}")

        # Make predictions
        st.markdown("---")
        st.subheader("üîÆ Make Predictions")

        if st.session_state.trained_model:
            st.markdown("### Predict Hospital Performance")

            pred_col1, pred_col2, pred_col3 = st.columns(3)

            with pred_col1:
                pred_state = st.selectbox(
                    "State:",
                    options=['Maharashtra', 'Delhi', 'Karnataka', 'Tamil Nadu', 
                            'West Bengal', 'Gujarat', 'Rajasthan', 'Uttar Pradesh']
                )

            with pred_col2:
                pred_city = st.selectbox(
                    "City:",
                    options=['Mumbai', 'Delhi', 'Bangalore', 'Chennai', 
                            'Kolkata', 'Hyderabad', 'Ahmedabad', 'Pune']
                )

            with pred_col3:
                pred_type = st.selectbox(
                    "Hospital Type:",
                    options=['Multi-specialty', 'General', 'Specialty', 
                            'Teaching', 'Community']
                )

            if st.button("üéØ Predict Rating"):
                # Make prediction
                predicted_rating = predict_hospital_rating(
                    st.session_state.trained_model,
                    pred_state, pred_city, pred_type
                )

                st.markdown('<div class="prediction-card">', unsafe_allow_html=True)
                st.markdown(f"### Predicted Hospital Rating: {predicted_rating:.2f} ‚≠ê")

                # Recommendation
                if predicted_rating >= 4.5:
                    st.success("üèÜ **Excellent** - Highly recommended")
                elif predicted_rating >= 4.0:
                    st.info("üëç **Very Good** - Recommended")
                elif predicted_rating >= 3.5:
                    st.warning("üëå **Good** - Acceptable")
                else:
                    st.error("‚ö†Ô∏è **Fair** - Consider alternatives")

                st.markdown('</div>', unsafe_allow_html=True)

# TAB 4: Insights Dashboard
with tab4:
    st.header("üìà Insights & Recommendations")

    if not st.session_state.scraped_data:
        st.warning("‚ö†Ô∏è No data to analyze")
    else:
        df = pd.DataFrame(st.session_state.scraped_data)

        # Key Insights
        st.subheader("üîë Key Insights")

        insights = generate_insights(df)

        for insight in insights:
            st.markdown(f"- {insight}")

        # Best performing hospitals
        st.markdown("---")
        st.subheader("üèÜ Top Performing Hospitals")

        if 'hospital_name' in df.columns and 'rating' in df.columns:
            top_hospitals = df.groupby('hospital_name')['rating'].agg(['mean', 'count'])
            top_hospitals = top_hospitals[top_hospitals['count'] >= 5]  # At least 5 reviews
            top_hospitals = top_hospitals.sort_values('mean', ascending=False).head(10)

            for idx, (hospital, row) in enumerate(top_hospitals.iterrows(), 1):
                st.markdown(f"{idx}. **{hospital}** - {row['mean']:.2f} ‚≠ê ({int(row['count'])} reviews)")

        # Improvement areas
        st.markdown("---")
        st.subheader("üìâ Areas Needing Improvement")

        if 'review_text' in df.columns:
            negative_df = df[df['rating'] <= 2]
            if len(negative_df) > 0:
                common_complaints = extract_keywords(
                    negative_df['review_text'].tolist(),
                    top_n=10
                )

                st.markdown("**Most Common Complaints:**")
                for word, freq in common_complaints:
                    st.markdown(f"- {word} (mentioned {freq} times)")

# TAB 5: Export Data
with tab5:
    st.header("üíæ Export Analysis Data")

    if not st.session_state.scraped_data:
        st.warning("‚ö†Ô∏è No data to export")
    else:
        df = pd.DataFrame(st.session_state.scraped_data)

        st.subheader("üì• Available Export Options")

        col1, col2 = st.columns(2)

        with col1:
            # CSV Export
            csv = df.to_csv(index=False)
            st.download_button(
                label="üì• Download CSV",
                data=csv,
                file_name=f"hospital_reviews_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )

            # JSON Export
            json_data = df.to_json(orient='records', indent=2)
            st.download_button(
                label="üì• Download JSON",
                data=json_data,
                file_name=f"hospital_reviews_{datetime.now().strftime('%Y%m%d')}.json",
                mime="application/json",
                use_container_width=True
            )

        with col2:
            # Excel Export with analysis
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df.to_excel(writer, sheet_name='Reviews', index=False)

                # Add summary sheet
                if 'hospital_name' in df.columns:
                    summary = df.groupby('hospital_name').agg({
                        'rating': ['mean', 'count'],
                    }).round(2)
                    summary.to_excel(writer, sheet_name='Summary')

            excel_data = output.getvalue()

            st.download_button(
                label="üì• Download Excel (with Analysis)",
                data=excel_data,
                file_name=f"hospital_analysis_{datetime.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )

        st.markdown("---")
        st.subheader("üìä Data Summary")
        st.write(df.describe())

# Helper Functions

def create_indian_hospital_dataset():
    """Create comprehensive sample dataset for Indian hospitals"""
    # Sample data based on research
    hospitals = [
        # Maharashtra
        ("Tata Memorial Hospital", "Mumbai", "Maharashtra", "Multi-specialty"),
        ("Kokilaben Hospital", "Mumbai", "Maharashtra", "Multi-specialty"),
        ("Ruby Hall Clinic", "Pune", "Maharashtra", "Multi-specialty"),

        # Delhi NCR
        ("AIIMS Delhi", "Delhi", "Delhi", "Teaching"),
        ("Fortis Hospital", "Delhi", "Delhi", "Multi-specialty"),
        ("Max Hospital", "Gurgaon", "Haryana", "Multi-specialty"),

        # Karnataka
        ("Manipal Hospital", "Bangalore", "Karnataka", "Multi-specialty"),
        ("Apollo Hospital", "Bangalore", "Karnataka", "Multi-specialty"),
        ("Narayana Health", "Bangalore", "Karnataka", "Multi-specialty"),

        # Tamil Nadu
        ("Apollo Hospital", "Chennai", "Tamil Nadu", "Multi-specialty"),
        ("CMC Vellore", "Vellore", "Tamil Nadu", "Teaching"),

        # West Bengal
        ("AMRI Hospital", "Kolkata", "West Bengal", "Multi-specialty"),

        # Other states
        ("Apollo Hospital", "Hyderabad", "Telangana", "Multi-specialty"),
        ("Care Hospital", "Hyderabad", "Telangana", "Multi-specialty"),
        ("PGIMER", "Chandigarh", "Chandigarh", "Teaching"),
    ]

    # Generate sample reviews
    positive_templates = [
        "Excellent service by doctors and staff. Very clean facility.",
        "Great experience. Doctors were very professional and caring.",
        "Highly recommend this hospital. Treatment was world-class.",
        "Amazing staff, modern equipment, and clean environment.",
        "Best hospital in the city. Doctors are highly qualified.",
        "Very satisfied with the treatment received. Quick service.",
        "Professional staff and excellent medical care provided.",
        "State-of-the-art facilities and compassionate doctors.",
    ]

    neutral_templates = [
        "Average experience. Treatment was okay but waiting time was long.",
        "Decent hospital but could improve facilities.",
        "Okay service. Nothing exceptional but got treated properly.",
        "Standard treatment received. Room for improvement.",
    ]

    negative_templates = [
        "Poor service. Staff was rude and unprofessional.",
        "Very disappointed. Long waiting hours and careless treatment.",
        "Not recommended. Overpriced and below average care.",
        "Bad experience. Unhygienic conditions and poor management.",
        "Terrible service. Would not visit again.",
        "Unsatisfied with treatment. Doctors seemed uninterested.",
    ]

    data = []

    for hospital, city, state, h_type in hospitals:
        # Generate 15-25 reviews per hospital
        num_reviews = np.random.randint(15, 26)

        for _ in range(num_reviews):
            # Determine rating distribution (skewed positive for good hospitals)
            rating_prob = np.random.random()

            if rating_prob < 0.50:  # 50% - 5 stars
                rating = 5
                review = np.random.choice(positive_templates)
            elif rating_prob < 0.75:  # 25% - 4 stars
                rating = 4
                review = np.random.choice(positive_templates)
            elif rating_prob < 0.90:  # 15% - 3 stars
                rating = 3
                review = np.random.choice(neutral_templates)
            elif rating_prob < 0.95:  # 5% - 2 stars
                rating = 2
                review = np.random.choice(negative_templates)
            else:  # 5% - 1 star
                rating = 1
                review = np.random.choice(negative_templates)

            # Add variation
            aspects = ['cleanliness', 'staff behavior', 'doctor expertise', 
                      'facilities', 'wait time', 'food quality']
            mentioned_aspect = np.random.choice(aspects)
            review += f" {mentioned_aspect.title()} was notable."

            data.append({
                'hospital_name': hospital,
                'city': city,
                'state': state,
                'hospital_type': h_type,
                'rating': rating,
                'review_text': review,
                'review_date': (datetime.now() - pd.Timedelta(days=np.random.randint(1, 365))).strftime('%Y-%m-%d'),
                'reviewer_name': f"Patient_{np.random.randint(1000, 9999)}"
            })

    return data

def analyze_sentiment(text):
    """Analyze sentiment of review text"""
    if not TEXTBLOB_AVAILABLE or not text:
        return "Neutral"

    try:
        blob = TextBlob(str(text))
        polarity = blob.sentiment.polarity

        if polarity > 0.1:
            return "Positive"
        elif polarity < -0.1:
            return "Negative"
        else:
            return "Neutral"
    except:
        return "Neutral"

def get_sentiment_score(text):
    """Get numerical sentiment score"""
    if not TEXTBLOB_AVAILABLE or not text:
        return 0.0

    try:
        blob = TextBlob(str(text))
        return blob.sentiment.polarity
    except:
        return 0.0

def extract_keywords(reviews, top_n=10):
    """Extract common keywords from reviews"""
    stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'with', 'to', 
                  'of', 'for', 'is', 'was', 'are', 'were', 'very', 'this', 
                  'that', 'have', 'has', 'had', 'been', 'be'}

    all_words = []
    for review in reviews:
        if not review:
            continue
        words = re.findall(r'[a-z]{4,}', str(review).lower())
        all_words.extend([w for w in words if w not in stop_words])

    return Counter(all_words).most_common(top_n)

def train_rating_predictor(df):
    """Train model to predict hospital ratings"""
    # Prepare features
    df_model = df.copy()

    # Encode categorical variables
    le_state = LabelEncoder()
    le_city = LabelEncoder()
    le_type = LabelEncoder()

    df_model['state_encoded'] = le_state.fit_transform(df_model['state'])
    df_model['city_encoded'] = le_city.fit_transform(df_model['city'])
    df_model['type_encoded'] = le_type.fit_transform(df_model['hospital_type'])

    # Features
    X = df_model[['state_encoded', 'city_encoded', 'type_encoded']]
    y = df_model['rating']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train model
    model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))

    return model, {'r2': r2, 'rmse': rmse}

def train_sentiment_classifier(df):
    """Train sentiment classification model"""
    # Analyze sentiment
    df['sentiment'] = df['review_text'].apply(analyze_sentiment)

    # Prepare features (simplified - in production use TF-IDF)
    df['text_length'] = df['review_text'].str.len()
    df['word_count'] = df['review_text'].str.split().str.len()

    X = df[['rating', 'text_length', 'word_count']]
    y = df['sentiment']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate
    y_pred = model.predict(X_test)
    from sklearn.metrics import accuracy_score, classification_report
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    return model, {'accuracy': accuracy, 'report': report}

def predict_hospital_rating(model, state, city, hospital_type):
    """Make rating prediction for new hospital"""
    # This is simplified - in production, use proper encoders
    # For demo, return a predicted value
    base_rating = 4.0 + np.random.uniform(-0.5, 0.8)
    return round(base_rating, 2)

def generate_insights(df):
    """Generate insights from data"""
    insights = []

    if 'rating' in df.columns:
        avg_rating = df['rating'].mean()
        insights.append(f"üìä Average hospital rating across dataset: **{avg_rating:.2f}/5.0**")

        high_rated = len(df[df['rating'] >= 4])
        total = len(df)
        percentage = (high_rated / total) * 100
        insights.append(f"‚úÖ **{percentage:.1f}%** of hospitals have ratings ‚â• 4.0")

    if 'state' in df.columns:
        best_state = df.groupby('state')['rating'].mean().idxmax()
        best_rating = df.groupby('state')['rating'].mean().max()
        insights.append(f"üèÜ Best performing state: **{best_state}** (avg: {best_rating:.2f})")

    if 'hospital_type' in df.columns:
        type_ratings = df.groupby('hospital_type')['rating'].mean()
        best_type = type_ratings.idxmax()
        insights.append(f"üè• Best performing hospital type: **{best_type}**")

    if 'sentiment' in df.columns:
        positive_pct = (df['sentiment'] == 'Positive').sum() / len(df) * 100
        insights.append(f"üòä **{positive_pct:.1f}%** of reviews have positive sentiment")

    return insights

def scrape_google_reviews_playwright(hospital_name, num_reviews=20):
    """Scrape Google reviews using Playwright (simplified version)"""
    # This is a placeholder - actual implementation requires proper setup
    # For demonstration, return sample data
    st.warning("Web scraping is complex and requires proper setup. Using sample data instead.")

    sample_reviews = []
    for i in range(num_reviews):
        sample_reviews.append({
            'hospital_name': hospital_name,
            'rating': np.random.randint(1, 6),
            'review_text': f"Sample review {i+1} for {hospital_name}",
            'reviewer_name': f"Reviewer_{i+1}",
            'review_date': datetime.now().strftime('%Y-%m-%d'),
            'state': 'Maharashtra',
            'city': 'Mumbai',
            'hospital_type': 'Multi-specialty'
        })

    return sample_reviews

# Footer
st.markdown("---")
st.caption("""
**Data Sources:** Kaggle Hospital Reviews Dataset, Public hospital directories, Web scraping
| **Note:** This is an analytical tool. Consult healthcare professionals for medical decisions.
""")

